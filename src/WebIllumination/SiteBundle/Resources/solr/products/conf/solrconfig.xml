<?xml version="1.0" encoding="UTF-8" ?>
<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->
<!--
     For more details about configurations options that may appear in this
     file, see http://wiki.apache.org/solr/SolrConfigXml.

     Specifically, the Solr Config can support XInclude, which may make it easier to manage
     the configuration.  See https://issues.apache.org/jira/browse/SOLR-1167
-->
<config>
    <!-- Set this to 'false' if you want solr to continue working after it has
         encountered an severe configuration error.  In a production environment,
         you may want solr to keep working even if one handler is mis-configured.

         You may also set this to false using by setting the system property:
           -Dsolr.abortOnConfigurationError=false
       -->
    <abortOnConfigurationError>${solr.abortOnConfigurationError:true}</abortOnConfigurationError>

    <!-- Used to specify an alternate directory to hold all index datai
         other than the default ./data under the Solr home.
         If replication is in use, this should match the replication configuration. -->
    <dataDir>/usr/local/lib/solr3/data/products</dataDir>


    <!-- WARNING: this <indexDefaults> section only provides defaults for index writers
         in general. See also the <mainIndex> section after that when changing parameters
         for Solr's main Lucene index. -->
    <indexDefaults>
        <!-- Values here affect all index writers and act as a default unless overridden. -->
        <useCompoundFile>false</useCompoundFile>
        <mergeFactor>10</mergeFactor>
        <ramBufferSizeMB>32</ramBufferSizeMB>
        <!-- <maxMergeDocs>2147483647</maxMergeDocs> -->
        <maxFieldLength>10000</maxFieldLength>
        <writeLockTimeout>1000</writeLockTimeout>
        <commitLockTimeout>10000</commitLockTimeout>
        <lockType>native</lockType>
    </indexDefaults>

    <mainIndex>
        <!-- options specific to the main on-disk lucene index -->
        <useCompoundFile>false</useCompoundFile>
        <ramBufferSizeMB>32</ramBufferSizeMB>
        <mergeFactor>10</mergeFactor>
        <!-- Deprecated -->
        <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
        <!--<maxMergeDocs>2147483647</maxMergeDocs>-->

        <!-- inherit from indexDefaults <maxFieldLength>10000</maxFieldLength> -->

        <!-- If true, unlock any held write or commit locks on startup.
             This defeats the locking mechanism that allows multiple
             processes to safely access a lucene index, and should be
             used with care.
             This is not needed if lock type is 'none' or 'single'
         -->
        <unlockOnStartup>false</unlockOnStartup>

        <!-- If true, IndexReaders will be reopened (often more efficient) instead
             of closed and then opened.  -->
        <reopenReaders>true</reopenReaders>

        <!--
         Expert:
        Controls how often Lucene loads terms into memory.  Default is 128 and is likely good for most everyone. -->
        <!--<termIndexInterval>256</termIndexInterval>-->

        <!--
            Custom deletion policies can specified here. The class must
            implement org.apache.lucene.index.IndexDeletionPolicy.

            http://lucene.apache.org/java/2_3_2/api/org/apache/lucene/index/IndexDeletionPolicy.html

            The standard Solr IndexDeletionPolicy implementation supports deleting
            index commit points on number of commits, age of commit point and
            optimized status.

            The latest commit point should always be preserved regardless
            of the criteria.
        -->
        <deletionPolicy class="solr.SolrDeletionPolicy">
            <!-- The number of commit points to be kept -->
            <str name="maxCommitsToKeep">1</str>
            <!-- The number of optimized commit points to be kept -->
            <str name="maxOptimizedCommitsToKeep">0</str>
            <!--
                Delete all commit points once they have reached the given age.
                Supports DateMathParser syntax e.g.

                <str name="maxCommitAge">30MINUTES</str>
                <str name="maxCommitAge">1DAY</str>
            -->
        </deletionPolicy>

        <!--  To aid in advanced debugging, you may turn on IndexWriter debug logging.
          Setting to true will set the file that the underlying Lucene IndexWriter
          will write its debug infostream to.  -->
        <infoStream file="INFOSTREAM.txt">false</infoStream>

    </mainIndex>
    <jmx />

    <!-- the default high-performance update handler -->
    <updateHandler class="solr.DirectUpdateHandler2">

    </updateHandler>

    <query>
        <!-- Maximum number of clauses in a boolean query... in the past, this affected
            range or prefix queries that expanded to big boolean queries - built in Solr
            query parsers no longer create queries with this limitation.
            An exception is thrown if exceeded.  -->
        <maxBooleanClauses>1024</maxBooleanClauses>

        <!-- Cache used by SolrIndexSearcher for filters (DocSets),
             unordered sets of *all* documents that match a query.
             When a new searcher is opened, its caches may be prepopulated
             or "autowarmed" using data from caches in the old searcher.
             autowarmCount is the number of items to prepopulate.  For LRUCache,
             the autowarmed items will be the most recently accessed items.
           Parameters:
             class - the SolrCache implementation LRUCache or FastLRUCache
             size - the maximum number of entries in the cache
             initialSize - the initial capacity (number of entries) of
               the cache.  (seel java.util.HashMap)
             autowarmCount - the number of entries to prepopulate from
               and old cache.
             -->
        <filterCache
                class="solr.FastLRUCache"
                size="512"
                initialSize="512"
                autowarmCount="0"/>

        <!-- queryResultCache caches results of searches - ordered lists of
              document ids (DocList) based on a query, a sort, and the range
              of documents requested.  -->
        <queryResultCache
                class="solr.LRUCache"
                size="512"
                initialSize="512"
                autowarmCount="0"/>

        <!-- documentCache caches Lucene Document objects (the stored fields for each document).
             Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
        <documentCache
                class="solr.LRUCache"
                size="512"
                initialSize="512"
                autowarmCount="0"/>

        <!-- If true, stored fields that are not requested will be loaded lazily.
          This can result in a significant speed improvement if the usual case is to
          not load all stored fields, especially if the skipped fields are large
          compressed text fields.
        -->
        <enableLazyFieldLoading>true</enableLazyFieldLoading>

        <!-- An optimization for use with the queryResultCache.  When a search
              is requested, a superset of the requested number of document ids
              are collected.  For example, if a search for a particular query
              requests matching documents 10 through 19, and queryWindowSize is 50,
              then documents 0 through 49 will be collected and cached.  Any further
              requests in that range can be satisfied via the cache.  -->
        <queryResultWindowSize>20</queryResultWindowSize>

        <!-- Maximum number of documents to cache for any entry in the
             queryResultCache. -->
        <queryResultMaxDocsCached>200</queryResultMaxDocsCached>

        <!-- If a search request comes in and there is no current registered searcher,
             then immediately register the still warming searcher and use it.  If
             "false" then all requests will block until the first searcher is done
             warming. -->
        <useColdSearcher>false</useColdSearcher>

        <!-- Maximum number of searchers that may be warming in the background
          concurrently.  An error is returned if this limit is exceeded. Recommend
          1-2 for read-only slaves, higher for masters w/o cache warming. -->
        <maxWarmingSearchers>2</maxWarmingSearchers>

    </query>

    <requestDispatcher handleSelect="true" >
        <!--Make sure your system has some authentication before enabling remote streaming!  -->
        <requestParsers enableRemoteStreaming="true" multipartUploadLimitInKB="2048000" />

        <httpCaching lastModifiedFrom="openTime"
                     etagSeed="Solr">
        </httpCaching>
    </requestDispatcher>


    <!-- requestHandler plugins... incoming queries will be dispatched to the
       correct handler based on the path or the qt (query type) param.
       Names starting with a '/' are accessed with the a path equal to the
       registered name.  Names without a leading '/' are accessed with:
        http://host/app/select?qt=name
       If no qt is defined, the requestHandler that declares default="true"
       will be used.
    -->
    <requestHandler name="standard" class="solr.SearchHandler" default="true">
        <!-- default values for query parameters -->
        <lst name="defaults">
            <str name="echoParams">explicit</str>
            <!--
            <int name="rows">10</int>
            <str name="fl">*</str>
            <str name="version">2.1</str>
             -->
        </lst>
    </requestHandler>

    <!-- Spell Check

         The spell check component can return a list of alternative spelling
         suggestions.

         http://wiki.apache.org/solr/SpellCheckComponent
      -->
    <searchComponent name="spellcheck" class="solr.SpellCheckComponent">

        <str name="queryAnalyzerFieldType">textSpell</str>

        <!-- Multiple "Spell Checkers" can be declared and used by this
             component
          -->

        <!-- a spellchecker built from a field of the main index, and
             written to disk
          -->
        <lst name="spellchecker">
            <str name="name">default</str>
            <str name="field">spelling</str>
            <str name="spellcheckIndexDir">spellchecker</str>
            <!-- uncomment this to require terms to occur in 1% of the documents
                 in order to be included in the dictionary
              -->
            <!--
                <float name="thresholdTokenFrequency">.01</float>
            -->
        </lst>
    </searchComponent>

    <!-- A request handler for demonstrating the spellcheck component.

         NOTE: This is purely as an example.  The whole purpose of the
         SpellCheckComponent is to hook it into the request handler that
         handles your normal user queries so that a separate request is
         not needed to get suggestions.

         IN OTHER WORDS, THERE IS REALLY GOOD CHANCE THE SETUP BELOW IS
         NOT WHAT YOU WANT FOR YOUR PRODUCTION SYSTEM!

         See http://wiki.apache.org/solr/SpellCheckComponent for details
         on the request parameters.
      -->
    <requestHandler name="/spell" class="solr.SearchHandler" startup="lazy">
        <lst name="defaults">
            <str name="df">spelling</str>
            <str name="spellcheck.onlyMorePopular">false</str>
            <str name="spellcheck.extendedResults">false</str>
            <str name="spellcheck.count">1</str>
        </lst>
        <arr name="last-components">
            <str>spellcheck</str>
        </arr>
    </requestHandler>

    <!-- Update request handler.

         Note: Since solr1.1 requestHandlers requires a valid content type header if posted in
         the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
         The response format differs from solr1.1 formatting and returns a standard error code.
         To enable solr1.1 behavior, remove the /update handler or change its path
      -->
    <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" />

    <!-- CSV update handler, loaded on demand -->
    <requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy" />


    <!-- Admin request handlers -->
    <requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />

    <!-- ping/healthcheck -->
    <requestHandler name="/admin/ping" class="PingRequestHandler">
        <lst name="defaults">
            <str name="qt">standard</str>
            <str name="q">solrpingquery</str>
            <str name="echoParams">all</str>
        </lst>
    </requestHandler>

    <highlighting>
        <!-- A regular-expression-based fragmenter (f.i., for sentence extraction) -->
        <fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
            <lst name="defaults">
                <!-- slightly smaller fragsizes work better because of slop -->
                <int name="hl.fragsize">70</int>
                <!-- allow 50% slop on fragment sizes -->
                <float name="hl.regex.slop">0.5</float>
                <!-- a basic sentence pattern -->
                <str name="hl.regex.pattern">[-\w ,/\n\"']{20,200}</str>
            </lst>
        </fragmenter>

        <!-- Configure the standard formatter -->
        <formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
            <lst name="defaults">
                <str name="hl.simple.pre"><![CDATA[<em>]]></str>
                <str name="hl.simple.post"><![CDATA[</em>]]></str>
            </lst>
        </formatter>
    </highlighting>

    <queryResponseWriter name="xslt" class="org.apache.solr.request.XSLTResponseWriter">
        <int name="xsltCacheLifetimeSeconds">5</int>
    </queryResponseWriter>


    <!-- example of registering a query parser
    <queryParser name="lucene" class="org.apache.solr.search.LuceneQParserPlugin"/>
    -->

    <!-- example of registering a custom function parser
    <valueSourceParser name="myfunc" class="com.mycompany.MyValueSourceParser" />
    -->

    <!-- config for the admin interface -->
    <admin>
        <defaultQuery>*:*</defaultQuery>

        <!-- configure a healthcheck file for servers behind a loadbalancer
        <healthcheck type="file">server-enabled</healthcheck>
        -->
    </admin>

</config>
